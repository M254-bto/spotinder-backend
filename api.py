# -*- coding: utf-8 -*-
"""API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Co0Z0uR_6kO6tRnbyFwGwDnIMK8VTZU-
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install flatten-dict

import requests
import pandas as pd
from flatten_dict import flatten

client_id = '4b7fa2bf3f504c359281219a68c48cab'
client_secret = '0f33ead49e17443387549b6dbe2fb04c'

myToken = 'BQC0rNSshfhTBsPRdFd_uMjiwgMGFK1MYgbvirMM3p5zFxZdorPmMyL-gB9P5F2ehN_ZOTNRBKHVSTR_PD_nW6l_F36hFsZkFssk1cr8TzgtKL8E2_2mWHNyODB4LKdAoJLglc6Rt_EIeZrmREdymnxF47XqjuZWxZf7zLEhNuf5n-TCaASERJXDElcpx-A4AylrLP2Xs6J0QMmqsR15aGviWZS_owIgOyo'
myUrl = 'https://api.spotify.com/v1/me/top/tracks?time_range=short_term&limit=50'
head = {'Authorization': 'Bearer {}'.format(myToken)}

res = requests.get(myUrl, headers=head).json()
songs = list(map(lambda i : {"id":i["id"],"name":i["name"],"popularity":i["popularity"], "uri":i["uri"], "preview_url":i["preview_url"]}, res['items']))

ids = ','.join([x['id'] for x in songs])
print(ids)

def song_features(id):
    url = f'https://api.spotify.com/v1/audio-features?ids={id}'
    features = requests.get(url, headers=head)
    print(url)
    return features.json()

feats = song_features(ids)

feats

ffeat = flatten(feats)

t_df = []
for i in ffeat.values():
  for j in i:

    t_df.append(j)

df = pd.DataFrame(t_df)

df.head()

from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA

def pre_processing(data):
  drop_cols = [x for x in ['year','name', 'explicit', 'id', 'release_date', 'artists'] if x in data.columns]
  scale_cols = [x for x in ['popularity', 'key']if x in data.columns]
  z_cols = ['valence', 'acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo']
  
  
  data.drop(data[drop_cols],axis=1, inplace=True)
  
  scaler = pd.DataFrame(MinMaxScaler().fit_transform(data[scale_cols]), columns = scale_cols)
  standard = pd.DataFrame(StandardScaler().fit_transform(data[z_cols]), columns = z_cols)
  processed_data = pd.concat([scaler, standard], axis=1, join='inner')

  

  pca = PCA(n_components=1).fit_transform(processed_data)
  return pca

df2 = pre_processing(df)

import pickle
model = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/Spotify classifier/song_cluster.pkl', 'rb'))

df['clusters'] = model.predict(df2)

df.head()

df['clusters'].value_counts().head(3)

